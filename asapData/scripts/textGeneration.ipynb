{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "\n",
    "This python notebook generates text based on a series of prompts. \n",
    "\n",
    "## Using Python Packages Without APIs\n",
    "\n",
    "### Using Hugging Face's gpt-J-6b model\n",
    "https://huggingface.co/EleutherAI/gpt-j-6B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies \n",
    "\n",
    "#if first time, run:   pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60cbdcfa2264bdf9c3a0a7bc5587572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e900ddac8141bd9a96b5ad1e4e84e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b5e9672c534a4aa5e2b542033a8c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d559aca1007e4bab812a9872eab23e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6528db53391048f5bf31f3e960027097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150b62e8eff842fe948ac2100afbf963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d2cd56055340d8917cb2caa77c37b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dc1cde610c435095e6b2407d4a0e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#using Hugging Face's gpt-j-6b\n",
    "#note that may need to install huggingface module(s): https://huggingface.co/welcome\n",
    "\n",
    "\n",
    "#code from https://huggingface.co/EleutherAI/gpt-j-6B\n",
    "\n",
    "#BE AWARE THIS CODE TAKES 20-40 MINUTES TO RUN\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using NLP Cloud's Instruct version of GPT-J\n",
    " #https://huggingface.co/nlpcloud/instruct-gpt-j-fp16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#Example code from Medium.com \n",
    " #https://medium.com/the-side-hustle-club/generate-text-content-with-7-lines-of-python-and-ai-4031ef5da5bf\n",
    "\n",
    "# CAUTION THIS CODE TAKES 60+ MINUTES TO RUN\n",
    "from transformers import pipeline\n",
    "\n",
    "# Select a task\n",
    "task = \"text-generation\"\n",
    "\n",
    "# Select a pre-trained model to use\n",
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "# Load Model from HuggingFace Hub\n",
    "text_gen = pipeline(task, model=model_name) \n",
    " #originally  text_gen = pipeline(task, model=model_name) \n",
    "\n",
    "# Define a baseline prompt for the generator\n",
    "base = \"I really like to play football, this sport is \"\n",
    "\n",
    "# Get generator's response\n",
    "res = text_gen(base, max_length=200)\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_xlsx(\"../../projectPlanning/datasetNotes.xlsx\", sheet = \"AIPrompts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
