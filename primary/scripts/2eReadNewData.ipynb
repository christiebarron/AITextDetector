{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save all the Human essays to a pandas dataframe and excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_directory = \"../rawData/HumanEssays/humanArgumentativeEssay/\"\n",
    "raw_excel_directory = \"../rawData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all the Human essays to a pandas dataframe ######\n",
    "\n",
    "text_list = [] #create a list to add text files to.\n",
    "ai_llm = [] #a list of the large language model used\n",
    "eid = [] #essay prompt id\n",
    "row_id = [] #final number\n",
    "files = os.listdir(raw_text_directory) #get a list of all file names within the directory\n",
    "filename_id = []\n",
    "\n",
    "#extract relevant information from ai-generated text files\n",
    "for f in files:\n",
    "    filename = f'{raw_text_directory}{f}' #save the filename\n",
    "\n",
    "    with open(filename, 'r') as f: #open filename and save the text in it\n",
    "        text_list.append(f.read())\n",
    "    \n",
    "    #append metadata saved in the filename (llm used, essay prompt, and row id)\n",
    "    filename_id.append(filename.split(\"/\")[4].split(\".\")[0])\n",
    "    \n",
    "    #ai_llm.append(filename.split(\"_\")[1])\n",
    "    #try:\n",
    "    #    eid.append(filename.split(\"_\")[0].split(\"d\")[1])\n",
    "    #except:\n",
    "    #    eid.append(f\"eid{filename.split('_')[0]}\")\n",
    "    #row_id.append(filename.split(\"_\")[2].split(\".\")[0])\n",
    "    \n",
    "    \n",
    "#save all extracted text to a pandas dataframe, then excel file.\n",
    "df = pd.DataFrame({\"original_id\" : filename_id, \"text\" : text_list})\n",
    "df.to_excel(f\"{raw_excel_directory}HumanArgumentative.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save all AI essays to a pandas dataframe and excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all AI essays to a pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "#save all the ai essays to a pandas dataframe ######\n",
    "working_directory = \"../rawData/aiEssays/\"#\"primary/rawData/aiEssays/\"\n",
    "clean_data_directory = \"../rawData/\" #\n",
    "\n",
    "\n",
    "text_list = [] #create a list to add text files to.\n",
    "ai_llm = [] #a list of the large language model used\n",
    "eid = [] #essay prompt id\n",
    "row_id = [] #final number\n",
    "files = os.listdir(working_directory) #get a list of all file names within the directory\n",
    "test1 = \"eid8_text-davinci-003_1352.txt\"\n",
    "test2 = \"8_gpt2_5059.txt\"\n",
    "test3 = 'eid21-the-good-ai_2909.txt'\n",
    "test4 = \"../rawData/aiEssays/eid7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eid7'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4.split(\"/\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df created successfully\n",
      "df saved as excel\n"
     ]
    }
   ],
   "source": [
    "#extract relevant information from ai-generated text files\n",
    "for document in files:\n",
    "    filename = f'{working_directory}{document}' #save the filename\n",
    "\n",
    "    with open(filename, 'r') as f: #open filename and save the text in it\n",
    "        text_list.append(f.read())\n",
    "    \n",
    "    #append metadata saved in the filename (llm used, essay prompt, and row id)\n",
    "    if \"the-good-ai\" in document:\n",
    "        document = f\"{document.split('-')[0]}_the-good-ai_{document.split('_')[1]}\" #rename file names from \"the-good-ai\" to match specification of below code\n",
    "        \n",
    "    ai_llm.append(document.split(\"_\")[1]) #second element is the LLM used to generate the text\n",
    "\n",
    "    if (document.split(\"_\")[0].startswith('e') == False):\n",
    "        eid.append(document.split('_')[0]) #for essays that weren't prefaced with \"eid\", just append the number\n",
    "        #print(document.split('_')[0])\n",
    "    else:\n",
    "        eid.append(document.split(\"_\")[0].split(\"d\")[1]) #if essays were prefaced w/ \"eid\", separate then just append the number\n",
    "        #print(document.split(\"_\")[0].split(\"d\")[1])\n",
    "\n",
    "    row_id.append(document.split(\"_\")[2].split(\".\")[0]) #append the row id, which is 3rd element.\n",
    "    \n",
    "#save all extracted text to a pandas dataframe, then excel file.\n",
    "df = pd.DataFrame({\"row_id\" : row_id, \"essay_id\" : eid, \"ai_llm\": ai_llm, 'ai_essay': text_list})\n",
    "print(\"df created successfully\")\n",
    "df.to_excel(f\"{clean_data_directory}aiGenerated.xlsx\")\n",
    "print(\"df saved as excel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
