{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a3addee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46a96d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data from the Excel file\n",
    "df = pd.read_excel('selected_essays 2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "581fbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Separate the features (X) and the target variable (y)\n",
    "target_column = 'ai_generated'\n",
    "X = df.drop(columns=[target_column,'ai_llm', 'avg_sentence_length.1', 'ai_llm', 'word_tokens', 'sentence_tokens', 'lemmatized_word_tokens', 'word_freq', 'bigram_freq', 'trigram_freq'])\n",
    "y = df[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66d80c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ab40ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply min-max scaling to ensure all features are non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b378f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Perform feature selection using SelectKBest with chi-squared scoring\n",
    "k = 7  # Replace 'k' with the number of top features you want to select\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d654c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the selected feature indices\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_feature_names = X.columns[selected_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2efff315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Train a machine learning model (Random Forest) using the selected features\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "31dd3906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Evaluate the model on the test set\n",
    "accuracy = model.score(X_test_selected, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60e09455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: (Optional) Get feature importances from the trained Random Forest model\n",
    "feature_importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': selected_feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8179abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                       Feature  Importance\n",
      "6                   smog_index    0.237797\n",
      "1              stop_word_count    0.174178\n",
      "4          flesch_reading_ease    0.162291\n",
      "2         avg_parse_tree_depth    0.161151\n",
      "0              avg_word_length    0.133219\n",
      "5   flesch_kincaid_grade_level    0.074525\n",
      "3  avg_adjectives_per_sentence    0.056840\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cdc18722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d0b5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Hyperparameter tuning for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a3dd0132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d7d30b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters and best model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e6767cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Trying different classification models\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train_selected, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e33351a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy: 0.8260869565217391\n",
      "SVM Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.82      0.82      0.82        23\n",
      "weighted avg       0.83      0.83      0.83        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate SVM model\n",
    "svm_y_pred = svm_model.predict(X_test_selected)\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "svm_classification_report = classification_report(y_test, svm_y_pred)\n",
    "print(\"SVM Model Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Model Classification Report:\")\n",
    "print(svm_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8de84c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9: Trying Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ec13984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.8260869565217391\n",
      "Logistic Regression Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.83        23\n",
      "   macro avg       0.82      0.82      0.82        23\n",
      "weighted avg       0.83      0.83      0.83        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate Logistic Regression model\n",
    "logistic_y_pred = logistic_model.predict(X_test_selected)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_y_pred)\n",
    "logistic_classification_report = classification_report(y_test, logistic_y_pred)\n",
    "print(\"Logistic Regression Model Accuracy:\", logistic_accuracy)\n",
    "print(\"Logistic Regression Model Classification Report:\")\n",
    "print(logistic_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1a72e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Evaluate all models\n",
    "rf_y_pred = grid_search.best_estimator_.predict(X_test_selected)\n",
    "svm_y_pred = svm_model.predict(X_test_selected)\n",
    "logistic_y_pred = logistic_model.predict(X_test_selected)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_y_pred)\n",
    "\n",
    "# Get unique class labels from the target variable\n",
    "classes = sorted(y_test.unique())\n",
    "\n",
    "rf_classification_report = classification_report(y_test, rf_y_pred, output_dict=True)\n",
    "svm_classification_report = classification_report(y_test, svm_y_pred, output_dict=True)\n",
    "logistic_classification_report = classification_report(y_test, logistic_y_pred, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "938dad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision_Human  Recall_Human  \\\n",
      "0        Random Forest  0.869565         0.777778      0.777778   \n",
      "1                  SVM  0.826087         0.777778      0.777778   \n",
      "2  Logistic Regression  0.826087         0.777778      0.777778   \n",
      "\n",
      "   F1-score_Human  Precision_AI  Recall_AI  F1-score_AI  \n",
      "0        0.777778      0.857143   0.857143     0.857143  \n",
      "1        0.777778      0.857143   0.857143     0.857143  \n",
      "2        0.777778      0.857143   0.857143     0.857143  \n"
     ]
    }
   ],
   "source": [
    "# Step 12: Create a summary DataFrame to compare the results\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'SVM', 'Logistic Regression'],\n",
    "    'Accuracy': [rf_accuracy, svm_accuracy, logistic_accuracy],\n",
    "    'Precision_Human': [logistic_classification_report['0']['precision'], svm_classification_report['0']['precision'], logistic_classification_report['0']['precision']],\n",
    "    'Recall_Human': [logistic_classification_report['0']['recall'], svm_classification_report['0']['recall'], logistic_classification_report['0']['recall']],\n",
    "    'F1-score_Human': [logistic_classification_report['0']['f1-score'], svm_classification_report['0']['f1-score'], logistic_classification_report['0']['f1-score']],\n",
    "    'Precision_AI': [logistic_classification_report['1']['precision'], svm_classification_report['1']['precision'], logistic_classification_report['1']['precision']],\n",
    "    'Recall_AI': [logistic_classification_report['1']['recall'], svm_classification_report['1']['recall'], logistic_classification_report['1']['recall']],\n",
    "    'F1-score_AI': [logistic_classification_report['1']['f1-score'], svm_classification_report['1']['f1-score'], logistic_classification_report['1']['f1-score']]\n",
    "})\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c64d8c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.94444444 0.94444444 0.88888889 0.77777778 0.88235294]\n",
      "Mean CV Score: 0.8875816993464053\n",
      "Feature Importances:\n",
      "                       Feature  Importance\n",
      "6                   smog_index    0.237797\n",
      "1              stop_word_count    0.174178\n",
      "4          flesch_reading_ease    0.162291\n",
      "2         avg_parse_tree_depth    0.161151\n",
      "0              avg_word_length    0.133219\n",
      "5   flesch_kincaid_grade_level    0.074525\n",
      "3  avg_adjectives_per_sentence    0.056840\n",
      "Test Accuracy: 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Cross-validation to evaluate the model's performance\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", cv_scores.mean())\n",
    "\n",
    "# Step 3: Analyze feature importances\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': selected_feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Finally, test the model on the test set\n",
    "test_accuracy = best_rf_model.score(X_test_selected, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e6bcc921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9230769230769231\n",
      "Recall: 0.8571428571428571\n",
      "F1-score: 0.888888888888889\n",
      "Train Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[ 8  1]\n",
      " [ 2 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_rf_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Check for potential overfitting\n",
    "train_accuracy = best_rf_model.score(X_train_selected, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9928fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Instances:\n",
      "              ai_llm  ai_generated  \\\n",
      "73   human-generated             0   \n",
      "97  text-davinci-003             1   \n",
      "91  text-davinci-003             1   \n",
      "\n",
      "                                          word_tokens  \\\n",
      "73  ['builders', 'attempting', 'build', 'dock', 'e...   \n",
      "97  ['remember', 'one', 'day', 'high', 'school', '...   \n",
      "91  ['line', 'one', 'evening', 'grocery', 'store',...   \n",
      "\n",
      "                                      sentence_tokens  \\\n",
      "73  ['the builders that were attempting to build a...   \n",
      "97  ['\\n\\ni remember one day in high school when i...   \n",
      "91  ['\\n\\ni was in line one evening at a grocery s...   \n",
      "\n",
      "                               lemmatized_word_tokens  total_word_count  \\\n",
      "73  ['builder', 'attempting', 'build', 'dock', 'em...               316   \n",
      "97  ['remember', 'one', 'day', 'high', 'school', '...               186   \n",
      "91  ['line', 'one', 'evening', 'grocery', 'store',...               197   \n",
      "\n",
      "    avg_word_length  avg_sentence_length       TTR  stop_word_count  ...  \\\n",
      "73         4.284810            24.545455  0.544304              113  ...   \n",
      "97         4.053763            16.900000  0.537634               94  ...   \n",
      "91         3.746193            16.272727  0.532995               96  ...   \n",
      "\n",
      "    avg_adjectives_per_sentence avg_adverbs_per_sentence  \\\n",
      "73                     2.363636                 1.181818   \n",
      "97                     0.600000                 0.800000   \n",
      "91                     0.636364                 1.272727   \n",
      "\n",
      "   avg_verbs_per_sentence avg_nouns_per_sentence  flesch_reading_ease  \\\n",
      "73               4.181818               7.727273                57.10   \n",
      "97               4.500000               3.000000                71.24   \n",
      "91               3.636364               3.000000                80.31   \n",
      "\n",
      "    flesch_kincaid_grade_level  smog_index  sentiment_polarity  \\\n",
      "73                          11        13.0            0.122448   \n",
      "97                           8        10.1            0.061984   \n",
      "91                           6         9.1            0.125000   \n",
      "\n",
      "    sentiment.subjectivity  perplexity  \n",
      "73                0.512884   54.542124  \n",
      "97                0.438449   86.161318  \n",
      "91                0.585000   96.234201  \n",
      "\n",
      "[3 rows x 28 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_filename.pkl']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find misclassified instances\n",
    "misclassified_indices = y_test.index[y_test != y_pred]\n",
    "\n",
    "# Get the misclassified instances from the original test set\n",
    "misclassified_instances = df.iloc[misclassified_indices]\n",
    "\n",
    "# Display the misclassified instances\n",
    "print(\"Misclassified Instances:\")\n",
    "print(misclassified_instances)\n",
    "\n",
    "# Save the trained model for future use and deployment\n",
    "import joblib\n",
    "joblib.dump(best_rf_model, 'model_filename.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dc3d605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai_llm</th>\n",
       "      <th>ai_generated</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>lemmatized_word_tokens</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>TTR</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_adjectives_per_sentence</th>\n",
       "      <th>avg_adverbs_per_sentence</th>\n",
       "      <th>avg_verbs_per_sentence</th>\n",
       "      <th>avg_nouns_per_sentence</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment.subjectivity</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human-generated</td>\n",
       "      <td>0</td>\n",
       "      <td>['dear', 'caps1', 'editor', 'think', 'computer...</td>\n",
       "      <td>['dear @caps1 editor, i think computers are a ...</td>\n",
       "      <td>['dear', 'caps1', 'editor', 'think', 'computer...</td>\n",
       "      <td>485</td>\n",
       "      <td>3.950515</td>\n",
       "      <td>16.884615</td>\n",
       "      <td>0.397938</td>\n",
       "      <td>236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>71.24</td>\n",
       "      <td>8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.315309</td>\n",
       "      <td>0.642392</td>\n",
       "      <td>95.445848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human-generated</td>\n",
       "      <td>0</td>\n",
       "      <td>['dear', 'caps1', 'post', 'computers', 'advanc...</td>\n",
       "      <td>['dear @caps1 post, computers are an advance i...</td>\n",
       "      <td>['dear', 'caps1', 'post', 'computer', 'advance...</td>\n",
       "      <td>576</td>\n",
       "      <td>3.715278</td>\n",
       "      <td>14.027778</td>\n",
       "      <td>0.425347</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>82.24</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.310374</td>\n",
       "      <td>0.491213</td>\n",
       "      <td>127.964146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human-generated</td>\n",
       "      <td>0</td>\n",
       "      <td>['dear', 'caps1', 'paper', 'editor', 'think', ...</td>\n",
       "      <td>['dear @caps1 paper editor, i think computers ...</td>\n",
       "      <td>['dear', 'caps1', 'paper', 'editor', 'think', ...</td>\n",
       "      <td>220</td>\n",
       "      <td>3.722727</td>\n",
       "      <td>17.727273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>68.60</td>\n",
       "      <td>9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.302273</td>\n",
       "      <td>0.537121</td>\n",
       "      <td>88.122713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human-generated</td>\n",
       "      <td>0</td>\n",
       "      <td>['organization1', 'use', 'computer', 'per', 'f...</td>\n",
       "      <td>['@organization1, the use of computer per fami...</td>\n",
       "      <td>['organization1', 'use', 'computer', 'per', 'f...</td>\n",
       "      <td>777</td>\n",
       "      <td>3.886744</td>\n",
       "      <td>15.688889</td>\n",
       "      <td>0.365508</td>\n",
       "      <td>370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.044444</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>4.177778</td>\n",
       "      <td>72.46</td>\n",
       "      <td>7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.412458</td>\n",
       "      <td>99.462260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human-generated</td>\n",
       "      <td>0</td>\n",
       "      <td>['dear', 'computer', 'technology', 'think', 'c...</td>\n",
       "      <td>['dear computer technology i think computers h...</td>\n",
       "      <td>['dear', 'computer', 'technology', 'think', 'c...</td>\n",
       "      <td>402</td>\n",
       "      <td>3.781095</td>\n",
       "      <td>26.357143</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>6.071429</td>\n",
       "      <td>70.06</td>\n",
       "      <td>12</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.290681</td>\n",
       "      <td>0.490789</td>\n",
       "      <td>91.679042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ai_llm  ai_generated  \\\n",
       "0  human-generated             0   \n",
       "1  human-generated             0   \n",
       "2  human-generated             0   \n",
       "3  human-generated             0   \n",
       "4  human-generated             0   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  ['dear', 'caps1', 'editor', 'think', 'computer...   \n",
       "1  ['dear', 'caps1', 'post', 'computers', 'advanc...   \n",
       "2  ['dear', 'caps1', 'paper', 'editor', 'think', ...   \n",
       "3  ['organization1', 'use', 'computer', 'per', 'f...   \n",
       "4  ['dear', 'computer', 'technology', 'think', 'c...   \n",
       "\n",
       "                                     sentence_tokens  \\\n",
       "0  ['dear @caps1 editor, i think computers are a ...   \n",
       "1  ['dear @caps1 post, computers are an advance i...   \n",
       "2  ['dear @caps1 paper editor, i think computers ...   \n",
       "3  ['@organization1, the use of computer per fami...   \n",
       "4  ['dear computer technology i think computers h...   \n",
       "\n",
       "                              lemmatized_word_tokens  total_word_count  \\\n",
       "0  ['dear', 'caps1', 'editor', 'think', 'computer...               485   \n",
       "1  ['dear', 'caps1', 'post', 'computer', 'advance...               576   \n",
       "2  ['dear', 'caps1', 'paper', 'editor', 'think', ...               220   \n",
       "3  ['organization1', 'use', 'computer', 'per', 'f...               777   \n",
       "4  ['dear', 'computer', 'technology', 'think', 'c...               402   \n",
       "\n",
       "   avg_word_length  avg_sentence_length       TTR  stop_word_count  ...  \\\n",
       "0         3.950515            16.884615  0.397938              236  ...   \n",
       "1         3.715278            14.027778  0.425347              274  ...   \n",
       "2         3.722727            17.727273  0.500000               96  ...   \n",
       "3         3.886744            15.688889  0.365508              370  ...   \n",
       "4         3.781095            26.357143  0.343284              206  ...   \n",
       "\n",
       "   avg_adjectives_per_sentence avg_adverbs_per_sentence  \\\n",
       "0                     1.384615                 1.307692   \n",
       "1                     0.583333                 1.166667   \n",
       "2                     1.636364                 1.000000   \n",
       "3                     0.933333                 1.044444   \n",
       "4                     0.714286                 0.928571   \n",
       "\n",
       "  avg_verbs_per_sentence avg_nouns_per_sentence  flesch_reading_ease  \\\n",
       "0               3.230769               3.769231                71.24   \n",
       "1               2.888889               3.166667                82.24   \n",
       "2               3.272727               5.454545                68.60   \n",
       "3               3.266667               4.177778                72.46   \n",
       "4               5.285714               6.071429                70.06   \n",
       "\n",
       "   flesch_kincaid_grade_level  smog_index  sentiment_polarity  \\\n",
       "0                           8        11.1            0.315309   \n",
       "1                           6         9.0            0.310374   \n",
       "2                           9        11.4            0.302273   \n",
       "3                           7        10.3            0.038129   \n",
       "4                          12        11.8            0.290681   \n",
       "\n",
       "   sentiment.subjectivity  perplexity  \n",
       "0                0.642392   95.445848  \n",
       "1                0.491213  127.964146  \n",
       "2                0.537121   88.122713  \n",
       "3                0.412458   99.462260  \n",
       "4                0.490789   91.679042  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find misclassified instances\n",
    "misclassified_indices = y_test.index[y_test != y_pred]\n",
    "\n",
    "# Drop misclassified instances from the original DataFrame\n",
    "df_cleaned = df.drop(index=misclassified_indices)\n",
    "\n",
    "# Display the cleaned DataFrame without the misclassified instances\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "37faff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9090909090909091\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.91        22\n",
      "   macro avg       0.91      0.91      0.91        22\n",
      "weighted avg       0.91      0.91      0.91        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load the cleaned data (df_cleaned)\n",
    "df = df_cleaned\n",
    "\n",
    "# Step 2: Separate the features (X) and the target variable (y)\n",
    "target_column = 'ai_generated'\n",
    "X = df.drop(columns=[target_column,'ai_llm', 'avg_sentence_length.1', 'ai_llm', 'word_tokens', 'sentence_tokens', 'lemmatized_word_tokens', 'word_freq', 'bigram_freq', 'trigram_freq'])\n",
    "y = df[target_column]\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Apply min-max scaling to ensure all features are in the same range\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 5: Perform feature selection using SelectKBest with chi-squared scoring\n",
    "k = 7  # Replace 'k' with the number of top features you want to select\n",
    "selector = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Step 6: Train a machine learning model (Random Forest) using the selected features\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 7: Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "\n",
    "# Step 8: Print the evaluation results\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f97c56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_excel('cleaned_df_project4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb597812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
